{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7c4c87",
   "metadata": {},
   "source": [
    "# Lesson 1: Router Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877df988",
   "metadata": {},
   "source": [
    "Welcome to Lesson 1.\n",
    "\n",
    "To access the `requirements.txt` file, the data/pdf file required for this lesson and the `helper` and `utils` modules, please go to the `File` menu and select`Open...`.\n",
    "\n",
    "I hope you enjoy this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c97c9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc9b4f4-64d4-4266-9889-54db90e00ee9",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc86df2",
   "metadata": {},
   "source": [
    "# Set up Ollama for embeddings as well as LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa4985ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set embedding model\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "ollama_embedding = OllamaEmbedding(\n",
    "    model_name='nomic-embed-text',\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")\n",
    "\n",
    "llm = Ollama(model='llama3.1', request_timeout=30.0)\n",
    "\n",
    "# Configure Settings singleton\n",
    "# Settings not needed - setting directly in the VectorStoreIndex call.\n",
    "Settings.embed_model = ollama_embedding\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fca250",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae2a8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "To download this paper, below is the needed code:\n",
    "\n",
    "#!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf\n",
    "\n",
    "**Note**: The pdf file is included with this lesson. To access it, go to the `File` menu and select`Open...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7f012d-dcd3-4881-a568-72dd27d79159",
   "metadata": {
    "height": 100,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File metagpt.pdf does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryReader\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# load documents\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleDirectoryReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetagpt.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mload_data()\n",
      "File \u001b[1;32mc:\\Users\\happy\\Documents\\Projects\\askgrowbuddy\\.venv\\Lib\\site-packages\\llama_index\\core\\readers\\file\\base.py:255\u001b[0m, in \u001b[0;36mSimpleDirectoryReader.__init__\u001b[1;34m(self, input_dir, input_files, exclude, exclude_hidden, errors, recursive, encoding, filename_as_id, required_exts, file_extractor, num_files_limit, file_metadata, raise_on_error, fs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m input_files:\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39misfile(path):\n\u001b[1;32m--> 255\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    256\u001b[0m     input_file \u001b[38;5;241m=\u001b[39m _Path(path)\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_files\u001b[38;5;241m.\u001b[39mappend(input_file)\n",
      "\u001b[1;31mValueError\u001b[0m: File metagpt.pdf does not exist."
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0aac02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mingest_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IngestService\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# The Directory containing the knowledge documents used by the AI to do the analysis on the soil tests.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m soil_knowledge_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMy Drive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAudios_To_Knowledge\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mknowledge\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAskGrowBuddy\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAskGrowBuddy\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mKnowledge\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msoil_test_knowlege\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.ingest_service import IngestService\n",
    "# The Directory containing the knowledge documents used by the AI to do the analysis on the soil tests.\n",
    "soil_knowledge_directory = r\"G:\\My Drive\\Audios_To_Knowledge\\knowledge\\AskGrowBuddy\\AskGrowBuddy\\Knowledge\\soil_test_knowlege\"\n",
    "# Load the documents\n",
    "\n",
    "ingest_service = IngestService()\n",
    "documents = ingest_service.load_obsidian_notes(soil_knowledge_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48a301",
   "metadata": {},
   "source": [
    "## Split into chunks. LlamaIndex likes the term nodes for chunks. I guess it sounds more Computer Sciencyish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a537bc0-78ee-4dda-a43f-60fd80062df6",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chunk text\n",
    "ingest_service = IngestService()\n",
    "nodes = ingest_service.chunk_text(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c7559",
   "metadata": {},
   "source": [
    "## Define Summary Index and Vector Index over the Same Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d01b01-bc74-432a-8d92-07b9e86498b0",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9898d3f",
   "metadata": {},
   "source": [
    "## Define Query Engines and Set Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd7046-c714-4920-b077-b3ded917862f",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d6d75-247e-426a-8ef4-b49225c24796",
   "metadata": {
    "height": 304,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to MetaGPT\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2c152",
   "metadata": {},
   "source": [
    "## Define Router Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00734d7c-638a-4d63-ab1f-7f5a92a65119",
   "metadata": {
    "height": 236,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f0a76-68a8-444d-867f-d084bb3ff112",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fedea0-f2a9-46bb-8aaf-287df65b8fff",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c31b3-8e22-4ad9-9825-b8de21bd03c0",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"How do agents share information with other agents?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed060ee",
   "metadata": {},
   "source": [
    "## Let's put everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f92e0b-1c54-489b-b8dd-41ebaafb380a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from utils import get_router_query_engine\n",
    "\n",
    "query_engine = get_router_query_engine(\"metagpt.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a43f3-77dc-472a-8adc-56551c00a0ff",
   "metadata": {
    "height": 66,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
