{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Goal\n",
    "The purpose of this notebook is:\n",
    "- to understand and choose a Markdown text splitter.  Is the splitter splitting in a way that makes sense?\n",
    "- to evaluate the contents of the text within the returned text splits.  Should the text be cleaned, are there nodes that are too large or too small?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is in the eval folder.  Change to the root folder.\n",
    "%cd ..\n",
    "%pwd  # To verify the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a cool library for printing data in a way that is easy to read.\n",
    "from rich import print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain's MarkdownTextSplitter\n",
    "I'm focusing on Langchain's splitters for now. I tried LlamaIndex's Markdown splitter but did not like the aggressiveness of the splitting.  First I'll try Langchain's `MarkdownTextSplitter`.\n",
    "\n",
    "The `MarkdownTextSplitter` is a `RecursiveCharacterTextSplitter` that has set the separators to include the Markdown headers. Here is how the splitter will split the text (see markdown.py):\n",
    "\n",
    "```\n",
    " elif language == Language.MARKDOWN:\n",
    "            return [\n",
    "                # First, try to split along Markdown headings (starting with level 2)\n",
    "                \"\\n#{1,6} \",\n",
    "                # Note the alternative syntax for headings (below) is not handled here\n",
    "                # Heading level 2\n",
    "                # ---------------\n",
    "                # End of code block\n",
    "                \"```\\n\",\n",
    "                # Horizontal lines\n",
    "                \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
    "                \"\\n---+\\n\",\n",
    "                \"\\n___+\\n\",\n",
    "                # Note that this splitter doesn't handle horizontal lines defined\n",
    "                # by *three or more* of ***, ---, or ___, but this is not handled\n",
    "                \"\\n\\n\",\n",
    "                \"\\n\",\n",
    "                \" \",\n",
    "                \"\",\n",
    "            ]\n",
    "```\n",
    "\n",
    "As shown in the simple example:\n",
    "- The chunk size and chunk overlap define the size of the text chunk. You can play around with these parameters and see how they affect the output.\n",
    "- No metadata is added or maintained during the splitting process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Specific Splitting - Markdown\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "splitter = MarkdownTextSplitter(chunk_size = 50, chunk_overlap=5)\n",
    "markdown_text = \"\"\"\n",
    "# Fun in California\n",
    "\n",
    "## Driving\n",
    "\n",
    "Try driving on the 1 down to San Diego\n",
    "\n",
    "### Food\n",
    "\n",
    "Make sure to eat a burrito while you're there\n",
    "\n",
    "## Hiking\n",
    "\n",
    "Go to Yosemite\n",
    "\"\"\"\n",
    "print(splitter.create_documents([markdown_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain's MarkdownHeaderTextSplitter\n",
    "The `MarkdownHeaderTextSplitter` does not inherit from `RecursiveCharacterTextSplitter`.  It's chunk size is defined by the header level specified in the `headers_to_split_on` list. This could mean really large or small chunks since it is based on the user's choice of headers. I could imagine an approach that starts here and then uses a `RecursiveCharacterTextSplitter` to clean up chunks broken on the header that are too large.\n",
    "\n",
    "Play around with the `headers_to_split_on` list to see how the splitting behaves.\n",
    "Notice:\n",
    "- The headers are included in the text of the chunk as well as the metadata.\n",
    "- The chunk size is defined by the header level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    # (\"##\", \"Header 2\"),\n",
    "    # (\"###\", \"Header 3\"),\n",
    "]\n",
    "splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on,strip_headers=False)\n",
    "\n",
    "print(splitter.split_text(markdown_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Obsidian Notes\n",
    "Based on the above, I'm focusing on the `MarkdownHeaderTextSplitter` for now. Let's large document and evaluate how text splitting looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingest_service import IngestService\n",
    "from src.doc_stats import DocStats\n",
    "ingest_service = IngestService()\n",
    "obsidian_notes_path = 'eval/obsidian_notes'\n",
    "# obsidian_notes_path = r'G:\\My Drive\\Audios_To_Knowledge\\knowledge\\AskGrowBuddy\\AskGrowBuddy\\Knowledge\\soil_test_knowlege'\n",
    "docs = ingest_service.load_obsidian_notes(obsidian_notes_path)\n",
    "\n",
    "DocStats.print_llama_index_docs_summary_stats(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingest_service import IngestService\n",
    "ingest_service = IngestService()\n",
    "nodes = ingest_service.chunk_text(docs)\n",
    "\n",
    "\n",
    "DocStats.print_llama_index_docs_summary_stats(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node_view import launch_node_viewer\n",
    "launch_node_viewer(nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
