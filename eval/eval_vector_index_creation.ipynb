{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Start\n",
    "This notebook documents:\n",
    "- Loading documents from a directory of an Obsidian vault into \"node\" objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load the Documents\n",
    "The `IngestService` has a method `load_obsidian_notes` that loads the notes from an Obsidian vault.  The input can be either a list of Document objects or a directory containing Obsidian notes.\n",
    "\n",
    "Using Obsidian notes provides several advantages:\n",
    "- Notes are easy to write and edit.\n",
    "- Frontmatter/tags transfer into the metadata of the nodes.\n",
    "- The Headers provide natural splitting points for the text.\n",
    "\n",
    "The `IngestService` class relies on Langchain's `ObsidianLoader` class to load the notes.  Langchain's loader is the only one I found that honored the Obsidian frontmatter, dataview fields, and tags to populate the metadata of the nodes.  Retrieval on metadata properties could be a powerful retrieval technique.\n",
    "\n",
    "The `load_obsidian_notes` method takes in either:\n",
    "- a list of strings where each string is considered a markdown file.\n",
    "- a directory path to an Obsidian vault.\n",
    "The list of strings options is useful for testing.\n",
    "\n",
    "It returns a list of `LlamaIndex` `Document` objects.  There will be one `LlamaIndex` `Document` for each node. The node will contain an id, text, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g. to show using the ability to read in a list of Documents to test out loading Documents.\n",
    "\n",
    "doc = \"\"\"#Calcium_additive #raise_ph #Wollastonite #Silicon_additive #buffer_pH #Calcium\n",
    "Growers  turn to Wollastonite for:\n",
    "- Its **liming** capability.  Wollastonite's dissolution rate is slower than agricultural lime, offering a buffering effect against rapid pH changes. This makes Wollastonite beneficial in areas with fluctuating acidity levels.\n",
    "- Adding **Silicon**.\n",
    "- Adding **Calcium**.\n",
    "Wollastonite's pH buffering effect and Silicon content contribute to pest control and powdery mildew suppression, although the exact mechanisms are not fully understood.\n",
    "\n",
    "# What is Wollastonite?\n",
    "\n",
    "## Formation\n",
    "Wollastonite is formed when Limestone is subjected to heat and pressure during metamorphism if surrounding silicate minerals are present.\n",
    "### Basic Reaction:\n",
    "Given high pressure and high temperature:\n",
    "- CaCO3 (Limestone) + SiO2 (silica) → CaSiO3 (Wollastonite) + CO2 (carbon Dioxide)\n",
    "## Sources\n",
    "China is the largest producer of Wollastonite. Other areas where Wollastonite is mined include the United States (although it was originally mined in California, the only active mining in the U.S. is now in New York State), India, Mexico, Canada, and Finland.\n",
    "\n",
    "## Industrial Applications of Wollastonite\n",
    "\n",
    "|Industry|Application|\n",
    "|---|---|\n",
    "|Ceramics|Smoother and more durable ceramics, reinforcement agent|\n",
    "|Plastics and Rubber|Cost-effective strengthening agent|\n",
    "|Paints and Coatings|Reinforcement, improved durability and impact resistance|\n",
    "|Construction|Improved strength and durability of building materials, safe alternative to asbestos|\n",
    "##  How Wollastonite Provides Plants with Ca and Si\n",
    "\n",
    "Wollastonite reacts with Water and Carbon Dioxide in the soil to form Calcium Bicarbonate and Silicon Dioxide.\n",
    "- CaSiO₃ (Wollastonite)+2CO₂ (carbon Dioxide,)+H₂O (Water)→Ca(HCO₃)₂ (Calcium bicarbonate)+SiO₂ (silica)\n",
    "\n",
    "### Calcium\n",
    "- Calcium bicarbonate  (Ca(HCO₃)₂) is unstable and fairly easily decomposes to Limestone (CaCO₃):\n",
    "\t\t- Ca(HCO₃)₂ (Calcium bicarbonate)→CaCO₃ (Limestone)+  CO₂ (carbon Dioxide) + H₂O (Water)\n",
    "\n",
    "- Soils with a pH below 7 (acidic soils) contain hydrogen ions (H+). These hydrogen ions react with the Limestone (CaCO3) to form Calcium ions (Ca2+), Water (H2O), and Carbon Dioxide (CO2).\n",
    "\t- CaCO3 (Limestone) + 2H+ (hydrogen ions) → Ca2+ (Calcium ions) + H2O (Water) + CO2 (carbon Dioxide)\n",
    "### Silicon\n",
    "- Silicon Dioxide slowly breaks down into Silicic Acid, which plants absorb. This process is influenced by soil pH, temperature, and microbial activity.\n",
    "\t- SiO2 (Silicon Dioxide) + 2H2O (Water) → H4SiO4 (Silicic Acid)\n",
    "\n",
    "- Plants absorb Silicic Acid from the soil solution through their roots.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit restart, then run this to start off with the right path for module resolution.\n",
    "# This notebook is in the eval folder.  Change to the root folder.\n",
    "%cd ..\n",
    "%pwd  # To verify the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --->: Read in the markdown files in the Obsidian vault directory\n",
    "from src.ingest_service import IngestService\n",
    "from src.doc_stats import DocStats\n",
    "# The Directory containing the knowledge documents used by the AI to do the analysis on the soil tests.\n",
    "soil_knowledge_directory = r\"G:\\My Drive\\Audios_To_Knowledge\\knowledge\\AskGrowBuddy\\AskGrowBuddy\\Knowledge\\soil_test_knowlege\"\n",
    "# Load the documents\n",
    "ingest_service = IngestService()\n",
    "loaded_documents = ingest_service.load_obsidian_notes(soil_knowledge_directory)\n",
    "# Show some summary stats about the documents\n",
    "\n",
    "DocStats.print_llama_index_docs_summary_stats(loaded_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A check for duplicate documents. The first time I loaded the documents, there were many duplicates. I added code to check and remove them.\n",
    "from rich import print\n",
    "from collections import defaultdict\n",
    "\n",
    "# Dictionary to keep track of how many times each document name has appeared\n",
    "doc_count = defaultdict(int)\n",
    "\n",
    "for doc in loaded_documents:\n",
    "    source = doc.metadata['source']\n",
    "    doc_count[source] += 1\n",
    "\n",
    "    if doc_count[source] > 1:\n",
    "        print(f\"{source} (Duplicate document. Document count: {doc_count[source]})\")\n",
    "    else:\n",
    "        print(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found duplicate documents, excalidraw documents, and code blocks that needed to be cleaned out of the documents. The `load_obsidian_notes` method handles removing some of these.  There are still challenges because there will be nodes with little to no, or meaningless, text.  It's a rabbithole probably worth exploring with a combination of pattern matching, nlp, and other replacement therapies. For now, after splitting the documents, I manually remove and pickle a \"GOOD\" collection of TextNodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Split the Documents using Markdown Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_nodes = ingest_service.chunk_text(loaded_documents)\n",
    "DocStats.print_llama_index_docs_summary_stats(text_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Review Unuseful Nodes\n",
    "After splitting the text, the contents of each node should be manually checked.  I spent several iterations on this process.  I evolved `loadObsidianNotes` based on manual review to automatically filter out some of the unuseful nodes. It is a \"hunt and peck\" activity.  If I was stronger in nlp, I would have a bigger toolbelt to filter the nodes through.  The ultimate goal is to have quality content in.\n",
    "\n",
    "I build the node_viewer. It is best to view the nodes by clicking on the URL. This brings up a Gradio interface. You can then view the text and metadata of each node.  You can also delete nodes from the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node_view import launch_node_viewer\n",
    "# Create and launch the interface\n",
    "launch_node_viewer(text_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I save and restore the text nodes to make it easier to pick up where I left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the nodes in case we want to start before indexing.\n",
    "import pickle\n",
    "with open('eval/text_nodes.pkl', 'wb') as f:\n",
    "    pickle.dump(text_nodes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is in the eval folder.  Change to the root folder.\n",
    "%cd ..\n",
    "%pwd  # To verify the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now unpickle\n",
    "import pickle\n",
    "\n",
    "with open('eval/text_nodes.pkl', 'rb') as f:\n",
    "    text_nodes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Build the Index\n",
    "Now onto building the vector index.  I was originally going to use LlamaIndex APIs to simplify the code, but I was getting frustrated with dumb bugs like the files weren't updated for Pydantic 2.  I stuck with the chroma apis after that. Even then, there was a challenge with the score. I discuss that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`chromadb` is used as the persistent store for the vector index.  I started using the SentenceTransformer embedding functions. I played around with different embedding functions.  For now, this one works ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 15:23:36,376 - src.ingest_service - INFO - Starting to build vector index with embedding model: multi-qa-mpnet-base-cos-v1 - c:\\Users\\happy\\Documents\\Projects\\askgrowbuddy\\src\\ingest_service.py:193\n",
      "2024-10-27 15:24:13,301 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: multi-qa-mpnet-base-cos-v1 - c:\\Users\\happy\\Documents\\Projects\\askgrowbuddy\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:216\n",
      "c:\\Users\\happy\\Documents\\Projects\\askgrowbuddy\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebbd190513f4ab28e2397e64c9a95dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The build_vector_index method does what is shown in the three cells after this one.\n",
    "from src.ingest_service import IngestService\n",
    "ingest_service = IngestService()\n",
    "collection = ingest_service.build_vector_index(nodes=text_nodes, collection_name='soil_test_knowledge', embed_model_name='multi-qa-mpnet-base-cos-v1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the collection of embeddings, the collection can be easily retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Collection</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">0004b352</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-3ce2-4004-bae6-dcd302a2a5a3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">docs_folder</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Collection</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">09f4d3e5</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-241a-4fa6-b425-f7ce1edac896</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">soil_test_comments</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Collection</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">2fc77243</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-63c8-4b60-8ac0-239d30e4db30</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">chunk</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>-overlap-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>-model-all-minilm<span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Collection</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">4c32c79f</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-3721-47a5-9a24-26429b7be650</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">test</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Collection</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">529b9786</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-a77c-4d48-aa3a-b5da2843a00a</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">atest</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Collection</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">5a1e8cef</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-4891-4045-8894-3f902ba5bf85</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">soil_test_knowledge</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Collection</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">741564d2</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-3b01-4558-b713-5b6ab5a561f0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">soil_test_comments_better_embedder</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Collection</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">86100c6e</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-d4e1-481b-8cff-0338df318fcf</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">asdfadfasdfadfsdfasdf</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Collection</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">e9f5a776</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-bd45-419c-a800-50e6445adb1a</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">thisisatews</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Collection</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #ffff00; text-decoration-color: #ffff00\">eabdf0ff</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-92c4-4ac4-acad-cd986a59bb64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">asdfadfasdfasdfasdfasdfasdfasdf</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mCollection\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[93m0004b352\u001b[0m\u001b[93m-3ce2-4004-bae6-dcd302a2a5a3\u001b[0m, \u001b[33mname\u001b[0m=\u001b[35mdocs_folder\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCollection\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[93m09f4d3e5\u001b[0m\u001b[93m-241a-4fa6-b425-f7ce1edac896\u001b[0m, \u001b[33mname\u001b[0m=\u001b[35msoil_test_comments\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCollection\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[93m2fc77243\u001b[0m\u001b[93m-63c8-4b60-8ac0-239d30e4db30\u001b[0m, \u001b[33mname\u001b[0m=\u001b[35mchunk\u001b[0m-\u001b[1;36m500\u001b[0m-overlap-\u001b[1;36m50\u001b[0m-model-all-minilm\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCollection\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[93m4c32c79f\u001b[0m\u001b[93m-3721-47a5-9a24-26429b7be650\u001b[0m, \u001b[33mname\u001b[0m=\u001b[35mtest\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCollection\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[93m529b9786\u001b[0m\u001b[93m-a77c-4d48-aa3a-b5da2843a00a\u001b[0m, \u001b[33mname\u001b[0m=\u001b[35matest\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCollection\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[93m5a1e8cef\u001b[0m\u001b[93m-4891-4045-8894-3f902ba5bf85\u001b[0m, \u001b[33mname\u001b[0m=\u001b[35msoil_test_knowledge\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCollection\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[93m741564d2\u001b[0m\u001b[93m-3b01-4558-b713-5b6ab5a561f0\u001b[0m, \u001b[33mname\u001b[0m=\u001b[35msoil_test_comments_better_embedder\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCollection\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[93m86100c6e\u001b[0m\u001b[93m-d4e1-481b-8cff-0338df318fcf\u001b[0m, \u001b[33mname\u001b[0m=\u001b[35masdfadfasdfadfsdfasdf\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCollection\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[93me9f5a776\u001b[0m\u001b[93m-bd45-419c-a800-50e6445adb1a\u001b[0m, \u001b[33mname\u001b[0m=\u001b[35mthisisatews\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCollection\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[93meabdf0ff\u001b[0m\u001b[93m-92c4-4ac4-acad-cd986a59bb64\u001b[0m, \u001b[33mname\u001b[0m=\u001b[35masdfadfasdfasdfasdfasdfasdfasdf\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import chromadb\n",
    "from rich import print\n",
    "# Show available collections\n",
    "chroma_client = chromadb.PersistentClient(path='vectorstore')\n",
    "collection_list = chroma_client.list_collections()\n",
    "\n",
    "print(collection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Number of nodes in the collection: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">115</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Number of nodes in the collection: \u001b[1;36m115\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "embedding_function = SentenceTransformerEmbeddingFunction(model_name='multi-qa-mpnet-base-cos-v1')\n",
    "chroma_client = chromadb.PersistentClient(path='vectorstore')\n",
    "collection_name = 'soil_test_knowledge'\n",
    "collection = chroma_client.get_collection(name=collection_name, embedding_function=embedding_function)\n",
    "print(f\"Number of nodes in the {collection} collection: {collection.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how well the index retrieves similar nodes to a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9701f24b0f0b4e8c9059935f5d15d658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Cosine Similarities:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Cosine Similarities:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8875638842582703</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Result \u001b[1;36m1\u001b[0m: \u001b[1;36m0.8875638842582703\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Source: <span style=\"font-weight: bold\">[</span>Tad Hussey YouTube<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.youtube.com/watch?v=CtdEHNjhhp8)</span>  \n",
       "**Target pH for Different Soil Types:**\n",
       "- In hydroponics, the common pH target is between <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.5</span> and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.0</span>.\n",
       "- Other soil companies may target a pH of around <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.6</span> for regular soils.\n",
       "- For living soils used in cannabis cultivation, \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Source: \u001b[1m[\u001b[0mTad Hussey YouTube\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.youtube.com/watch?\u001b[0m\u001b[4;94mv\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94mCtdEHNjhhp8\u001b[0m\u001b[4;94m)\u001b[0m  \n",
       "**Target pH for Different Soil Types:**\n",
       "- In hydroponics, the common pH target is between \u001b[1;36m5.5\u001b[0m and \u001b[1;36m6.0\u001b[0m.\n",
       "- Other soil companies may target a pH of around \u001b[1;36m6.6\u001b[0m for regular soils.\n",
       "- For living soils used in cannabis cultivation, \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.768328845500946</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Result \u001b[1;36m2\u001b[0m: \u001b[1;36m0.768328845500946\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">#soil_test  #M3 #Mehlic-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> #SP #saturated_paste  \n",
       "# Mehlic-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> and Saturated Paste Test results _2023_12  \n",
       "This discussion is based on the <span style=\"font-weight: bold\">[[</span>Margaret Johnson-Soil-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20231218</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">168413.</span>pdf<span style=\"font-weight: bold\">]]</span> M3 Report and <span style=\"font-weight: bold\">[[</span>Margaret \n",
       "Johnson-Saturated Paste-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20231218</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">168413.</span>pdf<span style=\"font-weight: bold\">]]</span> Saturated Paste Report.  \n",
       "The M3 <span style=\"font-weight: bold\">(</span>mehlic-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span> rep\n",
       "</pre>\n"
      ],
      "text/plain": [
       "#soil_test  #M3 #Mehlic-\u001b[1;36m3\u001b[0m #SP #saturated_paste  \n",
       "# Mehlic-\u001b[1;36m3\u001b[0m and Saturated Paste Test results _2023_12  \n",
       "This discussion is based on the \u001b[1m[\u001b[0m\u001b[1m[\u001b[0mMargaret Johnson-Soil-\u001b[1;36m20231218\u001b[0m-\u001b[1;36m168413.\u001b[0mpdf\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m M3 Report and \u001b[1m[\u001b[0m\u001b[1m[\u001b[0mMargaret \n",
       "Johnson-Saturated Paste-\u001b[1;36m20231218\u001b[0m-\u001b[1;36m168413.\u001b[0mpdf\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m Saturated Paste Report.  \n",
       "The M3 \u001b[1m(\u001b[0mmehlic-\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m rep\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.589678011619349</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Result \u001b[1;36m3\u001b[0m: \u001b[1;36m0.589678011619349\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># Phosphorous  \n",
       "Brandon noted he liked how Steve Solomon says Phosphorous <span style=\"color: #008000; text-decoration-color: #008000\">\"runs the motor\"</span>, and so if you're short on phosphorus \n",
       "you're going to get less uptake of all your other minerals as well , causing less growth.  Steve has a minimum \n",
       "target of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span> pounds of Phosphate <span style=\"font-weight: bold\">(</span>P2O5<span style=\"font-weight: bold\">)</span> per acre for cannab\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# Phosphorous  \n",
       "Brandon noted he liked how Steve Solomon says Phosphorous \u001b[32m\"runs the motor\"\u001b[0m, and so if you're short on phosphorus \n",
       "you're going to get less uptake of all your other minerals as well , causing less growth.  Steve has a minimum \n",
       "target of \u001b[1;36m400\u001b[0m pounds of Phosphate \u001b[1m(\u001b[0mP2O5\u001b[1m)\u001b[0m per acre for cannab\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5820777416229248</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Result \u001b[1;36m4\u001b[0m: \u001b[1;36m0.5820777416229248\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># Cation Balance  \n",
       "The discussion on Cation Balance delved into specific ratios and levels of major cations <span style=\"font-weight: bold\">(</span>calcium, magnesium, \n",
       "potassium, sodium<span style=\"font-weight: bold\">)</span> for cannabis cultivation. For example, they discussed maintaining calcium at <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>% of the \n",
       "cation exchange capacity <span style=\"font-weight: bold\">(</span>CEC<span style=\"font-weight: bold\">)</span> for optimal soil structure and\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# Cation Balance  \n",
       "The discussion on Cation Balance delved into specific ratios and levels of major cations \u001b[1m(\u001b[0mcalcium, magnesium, \n",
       "potassium, sodium\u001b[1m)\u001b[0m for cannabis cultivation. For example, they discussed maintaining calcium at \u001b[1;36m60\u001b[0m-\u001b[1;36m70\u001b[0m% of the \n",
       "cation exchange capacity \u001b[1m(\u001b[0mCEC\u001b[1m)\u001b[0m for optimal soil structure and\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5553413033485413</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Result \u001b[1;36m5\u001b[0m: \u001b[1;36m0.5553413033485413\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, similarity \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistances\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m[:\u001b[38;5;241m300\u001b[39m])\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "query = \"ideal ph for Cannabis\"\n",
    "# A collection retrieves a dictionary with a list of ids, documents, metadata as the main properties we are interested in.\n",
    "embedding_function = SentenceTransformerEmbeddingFunction(model_name='multi-qa-mpnet-base-cos-v1')\n",
    "results_dict = collection.query(query_texts=[query],  n_results=5)\n",
    "retrieved_documents = results_dict['documents'][0]\n",
    "# Convert cosine distances to cosine similarities\n",
    "results_dict['distances'][0] = [1 - distance for distance in results_dict['distances'][0]]\n",
    "\n",
    "# Print the results\n",
    "print(\"Cosine Similarities:\")\n",
    "for idx, similarity in enumerate(results_dict['distances'][0]):\n",
    "    print(f\"Result {idx}: {similarity}\")\n",
    "    print(results_dict['documents'][0][idx][:300])\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"distances\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \"The ideal ph for Cannabis is 6.8\"\n",
    "new_id = str(collection.count() + 1)\n",
    "new_metadata = {\"source\": \"manual_addition\"}\n",
    "# Add the new document to the collection\n",
    "collection.add(\n",
    "    documents=[new_text],\n",
    "    ids=[new_id],\n",
    "    metadatas=[new_metadata]\n",
    ")\n",
    "\n",
    "print(f\"Added new document with ID: {new_id}\")\n",
    "print(f\"New collection count: {collection.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cell to calculate cosine similarity using existing Visualize methods\n",
    "\n",
    "from src.visualize import Visualize\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize Visualize object (make sure to use the same parameters as before)\n",
    "visualize = Visualize()\n",
    "\n",
    "# Define your query and top_k\n",
    "query = \"Ideal ph for Cannabis.\"\n",
    "top_k = 5\n",
    "\n",
    "# Get relevant nodes and embeddings\n",
    "nodeswithscore = visualize._get_relevant_nodes(query, top_k)\n",
    "combined_embeddings, included_indices, n_samples, _ = visualize._prepare_embeddings(query, nodeswithscore)\n",
    "\n",
    "# Extract query embedding and document embeddings\n",
    "query_embedding = combined_embeddings[0]\n",
    "doc_embeddings = combined_embeddings[1:]\n",
    "\n",
    "# Calculate cosine similarities\n",
    "similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "\n",
    "# Get corresponding documents and ids\n",
    "results_dict = collection.query(query_texts=[query],  n_results=5)\n",
    "documents = results_dict['documents'][0]\n",
    "ids = results_dict['ids'][0]\n",
    "\n",
    "# Create a list of (id, document, similarity) tuples\n",
    "results = list(zip(ids, documents, similarities))\n",
    "\n",
    "# Sort by similarity (highest to lowest)\n",
    "results.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Print top results\n",
    "print(f\"Top {top_k} most similar documents:\")\n",
    "for id, doc, sim in results[:top_k]:\n",
    "    print(f\"ID: {id}\")\n",
    "    print(f\"Document: {doc[:100]}...\")  # Print first 100 characters\n",
    "    print(f\"Similarity: {sim}\")\n",
    "    print()\n",
    "\n",
    "# Compare with Chroma's results\n",
    "print(f\"\\nChroma's top {top_k} results:\")\n",
    "for node in nodeswithscore:\n",
    "    print(f\"ID: {node.node.id_}\")\n",
    "    print(f\"Document: {node.node.text[:100]}...\")\n",
    "    print(f\"Score: {node.score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize the tokenizer and embedding function\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/multi-qa-mpnet-base-cos-v1\")\n",
    "embedding_function = visualize.embedding_function\n",
    "\n",
    "query = \"ideal pH for Cannabis\"\n",
    "target_text = \"The ideal ph for Cannabis is 6.8\"\n",
    "\n",
    "# Get embeddings\n",
    "query_embedding = np.array(embedding_function([query])[0])\n",
    "target_embedding = np.array(embedding_function([target_text])[0])\n",
    "\n",
    "# Calculate cosine similarity manually\n",
    "dot_product = np.dot(query_embedding, target_embedding)\n",
    "query_norm = np.linalg.norm(query_embedding)\n",
    "target_norm = np.linalg.norm(target_embedding)\n",
    "manual_cosine_sim = dot_product / (query_norm * target_norm)\n",
    "\n",
    "# Calculate using sklearn for comparison\n",
    "sklearn_cosine_sim = cosine_similarity([query_embedding], [target_embedding])[0][0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Manual cosine similarity: {manual_cosine_sim}\")\n",
    "print(f\"Sklearn cosine similarity: {sklearn_cosine_sim}\")\n",
    "\n",
    "# Existing token analysis code...\n",
    "# (Keep the rest of the original cell's code here)\n",
    "\n",
    "# Add this at the end of the cell:\n",
    "print(\"\\nEmbedding analysis:\")\n",
    "print(f\"Query embedding shape: {query_embedding.shape}\")\n",
    "print(f\"Target embedding shape: {target_embedding.shape}\")\n",
    "print(f\"First 5 dimensions of query embedding: {query_embedding[:5]}\")\n",
    "print(f\"First 5 dimensions of target embedding: {target_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import numpy as np\n",
    "\n",
    "client = chromadb.Client()\n",
    "ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "\n",
    "# Test with \"cosine\" space\n",
    "collection_cosine = client.create_collection(\"test_cosine\", embedding_function=ef, metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "# Test with \"ip\" space\n",
    "collection_ip = client.create_collection(\"test_ip\", embedding_function=ef, metadata={\"hnsw:space\": \"ip\"})\n",
    "\n",
    "# Create two simple vectors\n",
    "vec1 = [1, 0]\n",
    "vec2 = [0, 1]\n",
    "\n",
    "# Add these to both collections\n",
    "collection_cosine.add(ids=[\"vec1\", \"vec2\"], embeddings=[vec1, vec2])\n",
    "collection_ip.add(ids=[\"vec1\", \"vec2\"], embeddings=[vec1, vec2])\n",
    "\n",
    "# Query using vec1 for both collections\n",
    "results_cosine = collection_cosine.query(query_embeddings=[vec1], n_results=2, include=[\"distances\"])\n",
    "results_ip = collection_ip.query(query_embeddings=[vec1], n_results=2, include=[\"distances\"])\n",
    "\n",
    "print(\"Cosine space results:\", results_cosine)\n",
    "print(\"IP space results:\", results_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"distances\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"documents\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = collection.query(query_texts=[query], n_results=5)\n",
    "\n",
    "# Print all keys in results_dict\n",
    "print(\"Keys in results_dict:\")\n",
    "for key in results_dict.keys():\n",
    "    print(f\"- {key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the results_dict into llama-index NodeWithScore.  We use NodeWithScore when working with the other retrievers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore, TextNode\n",
    "\n",
    "# Put results into a list of NodeWithScore objects\n",
    "nodes_with_score = []\n",
    "for i in range(len(results_dict['documents'][0])):\n",
    "    # Create a TextNode with the document text, metadata, id, and embedding\n",
    "    text_node = TextNode(\n",
    "        text=results_dict['documents'][0][i],\n",
    "        metadata=results_dict['metadatas'][0][i],\n",
    "        id_=results_dict['ids'][0][i]\n",
    "    )\n",
    "\n",
    "    # Create a NodeWithScore, using the distance directly as the score\n",
    "    node_with_score = NodeWithScore(node=text_node, score=results_dict['distances'][0][i])\n",
    "\n",
    "    nodes_with_score.append(node_with_score)\n",
    "\n",
    "# Now nodes_with_score is a list of NodeWithScore objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes_with_score:\n",
    "    print(f\"Node ID: {node.node.id_}, Type: {type(node.node.id_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualize import Visualize\n",
    "\n",
    "visualize = Visualize('soil_test_knowledge')\n",
    "visualize.plot_3d_umap(query, nodes_with_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualize import Visualize\n",
    "\n",
    "visualize = Visualize('soil_test_knowledge')\n",
    "visualize.plot_3d_plotly(query, nodes_with_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the retrieved documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict_keys(dictionary):\n",
    "    for key in dictionary.keys():\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "# What type of object is a document retrieved from the chroma collection?\n",
    "print(type(results))\n",
    "print_dict_keys(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the cosine similarity scores.\n",
    "print(results['distances'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analyzing results structure:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    if isinstance(result, dict):\n",
    "        print(\"Keys in this result:\")\n",
    "        for key in result.keys():\n",
    "            print(f\"  - {key}\")\n",
    "        if 'id' in result:\n",
    "            print(f\"ID found: {result['id']}\")\n",
    "    else:\n",
    "        print(f\"Type: {type(result)}\")\n",
    "        print(f\"Content: {str(result)[:50]}...\")  # Print first 50 characters\n",
    "\n",
    "    if i >= 4:  # Limit to first 5 results to avoid overwhelming output\n",
    "        print(\"\\n(Showing only first 5 results)\")\n",
    "        break\n",
    "\n",
    "print(\"\\nTotal number of results:\", len(list(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dict_keys(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(results['ids'][50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "print(f\"Successfully retrieved collection '{collection_name}'\")\n",
    "print(f\"Number of items: {len(results['ids'])}\")\n",
    "print(f\"Metadata sample: {results['metadatas'][0] if results['metadatas'] else 'No metadata'}\")\n",
    "print(f\"Document sample: {results['documents'][0] if results['documents'] else 'No documents'}\")\n",
    "print(f\"Embedding sample shape: {len(results['embeddings'][0]) if results['embeddings'] else 'No embeddings'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `build_vector_index` method using the chromadb apis.  Similar to below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup - load up the db and set up the embedding model that will be used during collection creation.\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "# The path to where the db is stored is fixed. The thought process is it simplifies the interface.\n",
    "chroma_client = chromadb.PersistentClient(path='vectorstore')\n",
    "collection_name = 'test'\n",
    "embed_model_name = 'multi-qa-mpnet-base-cos-v1'\n",
    "embedding_function = SentenceTransformerEmbeddingFunction(model_name=embed_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1.b Check embedding dimension\n",
    "sample_text = \"This is a sample text to check the embedding dimension.\"\n",
    "sample_embedding = embedding_function([sample_text])\n",
    "embedding_dim = len(sample_embedding[0])\n",
    "print(f\"Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the collection.  The documents will be embedded with the embedding function.  The metadata is added to the document as is an id.\n",
    "existing_collections = chroma_client.list_collections()\n",
    "if any(collection.name == collection_name for collection in existing_collections):\n",
    "    chroma_client.delete_collection(collection_name)\n",
    "    print(f\"Collection {collection_name} has been deleted.\")\n",
    "# The metadata field sets the distance field to cosine similarity.\n",
    "our_collection = chroma_client.create_collection( collection_name,embedding_function=embedding_function, metadata={\"hnsw:space\": \"cosine\"})\n",
    "ids = [str(i) for i in range(len(text_nodes))]\n",
    "documents = [node.text for node in text_nodes]\n",
    "metadata_list = [node.metadata for node in text_nodes]\n",
    "our_collection.add(ids=ids, documents=documents, metadatas = metadata_list)\n",
    "print(f\"Created collection '{collection_name}' with {our_collection.count()} document nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the vector index created, we can retrieve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "collection_name = \"microsoft_annual_report_2022\"\n",
    "try:\n",
    "    chroma_collection = chroma_client.create_collection( collection_name,embedding_function=embedding_function, metadata={\"hnsw:space\": \"cosine\"})\n",
    "    logger.debug(f'Chroma collection {collection_name} was created.')\n",
    "except:\n",
    "    chroma_client.delete_collection(collection_name)\n",
    "\n",
    "ids = [str(i) for i in range(len(text_nodes))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=text_nodes, metadatas = text_nodes.metadata)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the collection\n",
    "\n",
    "from src.ingest_service import IngestService\n",
    "ingest_service = IngestService()\n",
    "# Create a Chroma collection object of a given name. Metadata, embeddings, text are all added.\n",
    "our_collection = ingest_service.create_collection(docs=text_nodes, collection='soil_test_knowledge', embedding_model_name='snowflake-arctic-embed')\n",
    "# This will print the embedding dimension\n",
    "# print(our_collection.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check embedding dimension\n",
    "sample_text = \"This is a sample text to check the embedding dimension.\"\n",
    "sample_embedding = Settings.embed_model.get_text_embedding(sample_text)\n",
    "embedding_dim = len(sample_embedding)\n",
    "print(f\"Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our collection, we can create the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from src.ingest_service import IngestService\n",
    "# Grab the vector index\n",
    "ingest_service = IngestService()\n",
    "our_collection = ingest_service.get_collection('soil_test_knowledge')\n",
    "chroma_vector_store = ChromaVectorStore(chroma_collection=our_collection)\n",
    "# Create a VectorStoreIndex using the ChromaVectorStore\n",
    "vector_index = VectorStoreIndex.from_vector_store(chroma_vector_store, embed_model=Settings.embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve some documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_index.as_retriever(similarity_top_k=5,embed_model=Settings.embed_model)\n",
    "q = \"retrieve records that provide knowledge on the correct pH value for growing Cannabis as well as records that provide knowledge on what to do when the pH is too high or too low.\"\n",
    "\n",
    "nodes = retriever.retrieve(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node_view import print_node_scores\n",
    "print_node_scores(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node_view import launch_node_viewer\n",
    "# Create and launch the interface\n",
    "launch_node_viewer(nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
