{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Start\n",
    "Let's evolve our knowledge of embeddings.  We need to embed the text of nodes as well as the text of the question asked of the retriever.\n",
    "\n",
    "We are using LlamaIndex and Ollama.  Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%pwd  # To verify the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import os\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from pydantic import PrivateAttr\n",
    "# Create a custom Cohere embedding class\n",
    "class CohereEmbedding(BaseEmbedding):\n",
    "    _client: cohere.Client = PrivateAttr()\n",
    "    _model_name: str = PrivateAttr()\n",
    "    _input_type: str = PrivateAttr()\n",
    "\n",
    "    def __init__(self, model_name: str = \"embed-english-v3.0\", input_type: str = \"search_query\"):\n",
    "        super().__init__()\n",
    "        self._client = cohere.Client(api_key=os.getenv(\"COHERE_API_KEY\"))\n",
    "        self._model_name = model_name\n",
    "        self._input_type = input_type\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> list[float]:\n",
    "        embeddings = self._client.embed(texts=[query], model=self._model_name, input_type=self._input_type).embeddings\n",
    "        return embeddings[0]\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> list[float]:\n",
    "        embeddings = self._client.embed(texts=[text], model=self._model_name, input_type=self._input_type).embeddings\n",
    "        return embeddings[0]\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> list[float]:\n",
    "        # Cohere doesn't have an async API, so we'll just call the sync version\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str) -> list[float]:\n",
    "        # Cohere doesn't have an async API, so we'll just call the sync version\n",
    "        return self._get_text_embedding(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up ollama embedding for llama index.\n",
    "\n",
    "## Set embedding model\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "# Set up the Cohere embedding model\n",
    "Settings.embed_model = CohereEmbedding(\n",
    "    model_name=\"embed-english-v3.0\",\n",
    "    input_type=\"search_query\"\n",
    ")\n",
    "\n",
    "# Settings.embed_model = OllamaEmbedding(\n",
    "#     model_name='snowflake-arctic-embed',\n",
    "#     base_url=\"http://localhost:11434\",\n",
    "#     ollama_additional_kwargs={\"mirostat\": 0},\n",
    "# )\n",
    "## Choose your LLM...\n",
    "Settings.llm = Ollama(model='mistral', request_timeout=1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents.\n",
    "import pickle\n",
    "\n",
    "with open('text_nodes.pkl', 'rb') as f:\n",
    "    text_nodes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nodes[10].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02265961281955242, -0.005239610094577074, 0.07052355259656906, 0.02561274915933609, 0.10104447603225708, 0.028056371957063675, 0.010161704383790493, 0.02678683213889599, -0.010463953018188477, 0.013094304129481316, -0.00229410408064723, 0.024940816685557365, 0.03212709724903107, 0.05114594101905823, -0.13100771605968475, -0.044179853051900864, -0.02100180834531784, 0.0862240269780159, -0.1389358639717102, -0.006520877592265606, 0.025919483974575996, -0.043282076716423035, -0.00014383887173607945, -0.007276103366166353, -0.05586138367652893, 0.03298725187778473, -0.0278569757938385, -0.014384178444743156, 0.003727296367287636, 0.002785601420328021, -0.010051359422504902, 0.085335873067379, 0.08227475732564926, -0.012291735969483852, -0.00842922180891037, 0.0463767908513546, 0.053411033004522324, -0.02952464483678341, -0.011834043078124523, -0.005725303664803505, 0.049482561647892, -0.05733354762196541, 0.08487400412559509, 0.02219979465007782, 0.002378671197220683, -0.05349179729819298, 0.030639750882983208, -0.1163962259888649, -0.040765181183815, 0.006551963277161121, 0.02296222187578678, 0.009871757589280605, 0.05030389130115509, -0.043100953102111816, -0.13169530034065247, -0.007287298794835806, 0.027358263731002808, -0.0024460034910589457, -0.041259028017520905, 0.023471496999263763, 0.03642265871167183, -0.006728074047714472, -0.06223341077566147, -0.05064310133457184, 0.07032003998756409, -0.004446067381650209, -0.0021008201874792576, -0.018578482791781425, 0.013694798573851585, 0.013776962645351887, -0.05433371290564537, 0.06527383625507355, 0.07904302328824997, -0.01057844702154398, -0.03008595108985901, 0.04138960316777229, -0.05823895335197449, -0.035291530191898346, 0.009810241870582104, 0.01223165076225996, 0.07174845039844513, 0.008107177913188934, 0.0046209655702114105, -0.016765451058745384, 0.022678442299365997, 0.027094494551420212, -0.0026590756606310606, -0.005507640074938536, -0.05275644734501839, -0.08752042800188065, 0.06842127442359924, -0.00740678608417511, -0.06953302025794983, 0.04651838168501854, -0.02160387672483921, 0.11017926782369614, -0.008896994404494762, -0.06340675055980682, -0.053683485835790634, 0.011018218472599983, 0.004746158141642809, 0.03167188912630081, -0.011077706702053547, 0.0037554253358393908, 0.0966019555926323, -0.04070809483528137, -0.015941230580210686, -0.07943038642406464, -0.00467901723459363, 0.0590798556804657, 0.013921890407800674, 0.005877409130334854, -0.02607065998017788, 0.021779607981443405, 0.04591238498687744, 0.017060304060578346, 0.015282224863767624, -0.005776125006377697, -0.06736749410629272, -0.011742625385522842, 0.02867337502539158, -0.06579449772834778, 0.027146799489855766, 0.015364632941782475, 0.1417335718870163, 0.07181790471076965, -0.017704103142023087, 2.676963570703165e-33, 0.031482577323913574, -0.02007986418902874, 0.04966573044657707, -0.004555580206215382, -0.07592374086380005, -0.020518982782959938, 0.010538275353610516, -0.002035687677562237, 0.03731948137283325, -0.03551896661520004, -0.02847621776163578, 0.06947169452905655, -0.00671308021992445, -0.05010206624865532, -0.06158793717622757, 0.055290017277002335, 0.01508767157793045, -0.03818051144480705, 0.05661460757255554, 0.02309640310704708, 0.03530358150601387, -0.1298942267894745, -0.052565574645996094, 0.0184654351323843, -0.03572768718004227, -0.05478956177830696, 0.0029819088522344828, 0.03624260798096657, 0.05477047711610794, -0.02372872643172741, 0.02994861640036106, -0.01582830585539341, -0.0604301393032074, 0.06588380038738251, -0.00023892799799796194, 0.0031586079858243465, -0.06579319387674332, 0.022622307762503624, -0.009758410044014454, 0.03224064037203789, -0.017550058662891388, 0.004736813250929117, 0.09745829552412033, 0.07421570271253586, 0.1008506789803505, -0.03262535482645035, -0.10912282764911652, 0.005781965795904398, 0.07247451692819595, 0.028421035036444664, -0.014329836703836918, 0.001957680331543088, -0.01448951568454504, 0.02540808916091919, -0.014280945062637329, -0.024208012968301773, 0.02442242205142975, -0.062251120805740356, -0.07963449507951736, 0.05608873441815376, -0.06153002008795738, -0.02069944702088833, -0.039390526711940765, 0.04537409171462059, -0.041326284408569336, 0.03701440244913101, -0.03446173295378685, 0.015376243740320206, 0.06060734763741493, 0.010292215272784233, -0.07804320752620697, -0.06267566978931427, -0.04657478258013725, 0.04363485053181648, -0.0440075621008873, -0.031040791422128677, 0.03174972161650658, 0.032185234129428864, -0.02996050752699375, 0.006839377339929342, 0.11643955111503601, -0.05798343941569328, 0.010584005154669285, 0.11770699918270111, -0.09863870590925217, -0.04963047802448273, -0.006006533280014992, -0.0032412398140877485, 0.033556461334228516, -0.050794634968042374, 0.07882044464349747, 0.05567115545272827, -0.0022150068543851376, -0.06218216195702553, 0.02735820971429348, -3.5238521491729284e-33, 0.06197349727153778, 0.02298259176313877, -0.10725273191928864, 0.08208692073822021, 0.02998851239681244, -0.035005588084459305, 0.06486416608095169, -0.042662911117076874, 0.03492366150021553, -0.04507865011692047, -0.025140386074781418, 0.019064025953412056, -0.012633578851819038, -0.02452443540096283, -0.0770234763622284, 0.022391099482774734, -0.06323058903217316, 0.012254532426595688, 0.034429825842380524, 0.008496426045894623, -0.06185681372880936, 0.0822189450263977, 0.03993179276585579, 0.0014591427752748132, -0.029782356694340706, -0.02543533220887184, 0.010187027975916862, -0.06015130877494812, -0.08767741173505783, 0.0425577275454998, 0.062033604830503464, 0.05864788964390755, -0.03404226154088974, 0.02602047473192215, 0.016642602160573006, -0.08025378733873367, -0.012653619982302189, -0.12174705415964127, -0.011387817561626434, 0.1411142498254776, 0.016915518790483475, 0.03624945506453514, 0.06234550476074219, -0.029007859528064728, -0.004139556083828211, 0.11153236776590347, 0.09736695140600204, -0.07253312319517136, -0.014086979441344738, 0.004464727360755205, 0.11613704264163971, 0.04222532734274864, -0.040524937212467194, 0.033092401921749115, 0.033449336886405945, -0.0005384812830016017, -0.0666557103395462, 0.00997132621705532, -0.07737698405981064, 0.12035823613405228, 0.02172539383172989, 0.013803662732243538, -0.07231252640485764, -0.03677034378051758, -0.12532490491867065, 0.004783277865499258, 0.07700924575328827, 0.0900164321064949, 0.08448129147291183, -0.020456135272979736, -0.011785866692662239, -0.08834465593099594, 0.0903882160782814, -0.0022975190076977015, -0.005183432251214981, 0.041365042328834534, -0.08551593124866486, -0.004121396224945784, -0.045822128653526306, -0.02139052003622055, -0.08063479512929916, -0.004456142894923687, -0.10160190612077713, -0.020448455587029457, -0.0028363338205963373, -0.01922517642378807, -0.006629227194935083, -0.046587422490119934, -0.027166321873664856, 0.013308020308613777, 0.038578763604164124, -0.09519283473491669, -0.06010211259126663, 0.020048990845680237, 0.030818594619631767, -5.634971955714718e-08, 0.008712862618267536, 0.001354522886686027, -0.07183120399713516, -0.04970043525099754, -0.05992135778069496, -0.01596135087311268, 0.06077896058559418, -0.005107420030981302, 0.04390648379921913, 0.08733547478914261, -0.024811163544654846, -0.006312658078968525, -0.0899093970656395, 0.02412414364516735, 0.04891806095838547, 0.02352340705692768, 0.07596711814403534, 0.014272096566855907, -0.061705972999334335, 0.04928627982735634, -0.02640705555677414, -0.03166715055704117, -0.0777675062417984, 0.049827709794044495, 0.0516417995095253, -7.240059494506568e-05, 0.07085522264242172, 0.019323844462633133, -0.0037410021759569645, 0.008381335064768791, 0.09026186913251877, 0.007531740237027407, 0.019190091639757156, -0.0171766709536314, 0.025255858898162842, 0.10810403525829315, -0.020308194682002068, -0.021405745297670364, 0.05393777787685394, 0.07985971122980118, -0.09653709828853607, 0.011175584979355335, -0.09529957920312881, -0.021959180012345314, -0.024497808888554573, -0.020388709381222725, -0.029858455061912537, 0.0525876060128212, 0.02512821927666664, -0.016083568334579468, -0.015018186531960964, -0.020127570256590843, 0.027706019580364227, -0.06523822993040085, 0.0003114764695055783, 0.07544618844985962, 0.049867916852235794, -0.005462405737489462, -0.049965742975473404, -0.019228873774409294, 0.012019925750792027, 0.036433905363082886, -0.012013617902994156, -0.09582100808620453]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "print(embedding_function([text_nodes[10].text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "collection_name = \"microsoft_annual_report_2022\"\n",
    "# Check if the collection exists and delete it if it does\n",
    "try:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "    print(f\"Existing collection '{collection_name}' deleted.\")\n",
    "except ValueError:\n",
    "    print(f\"Collection '{collection_name}' does not exist. Proceeding to create.\")\n",
    "chroma_collection = chroma_client.create_collection(collection_name, embedding_function=embedding_function)\n",
    "# Extract text from each node\n",
    "documents = [node.text for node in text_nodes]\n",
    "ids = [str(i) for i in range(len(text_nodes))]\n",
    "metadatas = [node.metadata for node in text_nodes]\n",
    "chroma_collection.add(ids=ids, documents=documents, metadatas=metadatas)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector index.\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex.from_documents(text_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_nodes[0].metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
