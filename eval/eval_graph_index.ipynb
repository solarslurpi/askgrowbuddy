{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Start\n",
    "This notebook documents the process of creating a graph index from Obsidian notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is in the eval folder.  Change to the root folder.\n",
    "%cd ..\n",
    "%pwd  # To verify the current working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the documents\n",
    "First we need some TextNode objects. I put 3 documents within the `test` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --->: Read in the markdown files in the Obsidian vault directory\n",
    "from src.doc_stats import DocStats\n",
    "from src.ingest_service import IngestService\n",
    "\n",
    "# The Directory containing the knowledge documents used by the AI to do the analysis on the soil tests.\n",
    "soil_knowledge_directory = r\"G:\\My Drive\\Audios_To_Knowledge\\knowledge\\AskGrowBuddy\\AskGrowBuddy\\Knowledge\\soil_test_knowlege\\test\"\n",
    "# Load the documents\n",
    "ingest_service = IngestService()\n",
    "loaded_documents = ingest_service.load_obsidian_notes(soil_knowledge_directory)\n",
    "# Show some summary stats about the documents\n",
    "DocStats.print_llama_index_docs_summary_stats(loaded_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Text Nodes\n",
    "This is discussed more in the notebook where the vector index is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nodes = ingest_service.chunk_text(loaded_documents)\n",
    "DocStats.print_llama_index_docs_summary_stats(text_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the nodes\n",
    "Let's look at the contents of the nodes.  Open up the link to view the nodes in the browser.  There are three files in the `test` directory.  You can see these in the node viewer by looking at the source.\n",
    "- `ph.md` is one node.\n",
    "- `soil science notes.md` has 33 nodes.\n",
    "- `Focusing on Calcium Nutrition.md` has has also one node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node_view import launch_node_viewer\n",
    "\n",
    "# Create and launch the interface\n",
    "launch_node_viewer(text_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Knowledge Graph (not batch mode)\n",
    "The method `build_knowledge_graph()` in `knowledge_graph.py` encapsulates creating our knowledge graph.  I am new to using a knowledge graph. I ended up:\n",
    "- evolving LlamaIndex's `PropertyGraphIndex` class and rewriting it.\n",
    "- using neo4j to store the graph.\n",
    "\n",
    "In order to create the graph index, an LLM is used to extract triplets from the text.  These triplets are then used to create the graph in neo4j. This is a costly token consuming process.  I ended up using Ollama LLMs for testing and Anthropic's claude sonet for the final version.\n",
    "\n",
    "__Note: neo4j must be running to create the graph index.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.knowledge_graph import BuildGraphIndex\n",
    "\n",
    "# kg_builder = BuildGraphIndex()\n",
    "# kg_index = kg_builder.build_graph_index(\n",
    "#     text_nodes=text_nodes, database_name=\"test\", llm_model_name=\"mistral_soil\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Knowledge Graph - Batch mode\n",
    "I use Antrhopic's Claude Sonnet 3.5 to build the final version. Anthropic has a batch API that cuts the cost in half.  The way it works is you submit a batch of requests.  The API returns a batch id.  You poll the API until the batch is complete. Then retrieve the results.\n",
    "\n",
    "Here is what the return is to a call to Anthropic's `create_batch()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\n",
    "  \"id\": \"msgbatch_01EMPAyqx1B2mXtiD4EqMCvR\",\n",
    "  \"type\": \"message_batch\",\n",
    "  \"processing_status\": \"in_progress\",\n",
    "  \"request_counts\": {\n",
    "    \"processing\": 35,\n",
    "    \"succeeded\": 0,\n",
    "    \"errored\": 0,\n",
    "    \"canceled\": 0,\n",
    "    \"expired\": 0\n",
    "  },\n",
    "  \"created_at\": \"2024-11-04T17:27:01.482961+00:00\",\n",
    "  \"ended_at\": None,\n",
    "  \"expires_at\": \"2024-11-05T17:27:01.482961+00:00\",\n",
    "  \"archived_at\": None,\n",
    "  \"cancel_initiated_at\": None,\n",
    "  \"results_url\": None,\n",
    "  \"time_remaining\": \"20:53:12\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new batch job\n",
    "It is easy to create a new batch job. Pass in the text nodes to the `create_batch()` method. An object of type `BetaMessmageBatch` is returned. The field returned can be seen in `BuildGraphIndexBatch.check_batch_status()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.knowledge_graph_batch import BuildGraphIndexBatch\n",
    "kg_builder_batch = BuildGraphIndexBatch()\n",
    "# Ask the llm to create triplets from the text in the nodes.  These triplets are then stored in neo4j as the knowledge graph.\n",
    "batch = kg_builder_batch.create_batch(text_nodes)\n",
    "# Save the batch ID in order to eventually retreive results after the batch job runs.\n",
    "kg_builder_batch.save_batch_id(batch.id)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Status\n",
    "Check the status of the last batch job that was submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src.knowledge_graph_batch import BuildGraphIndexBatch\n",
    "kg_builder_batch = BuildGraphIndexBatch()\n",
    "batch_id = kg_builder_batch.load_batch_id(\"batch_status.json\")\n",
    "batch_id = 'msgbatch_01L3c152bCazJSgTRKNJkVsm'\n",
    "status = kg_builder_batch.check_batch_status(batch_id)\n",
    "print(json.dumps(status, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Batch Jobs\n",
    "We can list the batch jobs that have been sent in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch_summary(batches):\n",
    "    for batch in batches.data:\n",
    "        print(f\"\\nBatch ID: {batch.id}\")\n",
    "        print(f\"Status: {batch.processing_status}\")\n",
    "        print(f\"Created: {batch.created_at}\")\n",
    "        print(f\"Ended: {batch.ended_at}\")\n",
    "        print(\"Request Counts:\")\n",
    "        print(f\"  Processing: {batch.request_counts.processing}\")\n",
    "        print(f\"  Succeeded: {batch.request_counts.succeeded}\")\n",
    "        print(f\"  Errored: {batch.request_counts.errored}\")\n",
    "        print(f\"  results URL: {batch.results_url}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.knowledge_graph_batch import BuildGraphIndexBatch\n",
    "kg_builder_batch = BuildGraphIndexBatch()\n",
    "batches = kg_builder_batch.list_batches()\n",
    "print_batch_summary(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Batch Results\n",
    "The batch results are retrieved and then saved so that we can process them locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from src.knowledge_graph_batch import BuildGraphIndexBatch\n",
    "\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "results = client.beta.messages.batches.results(\"msgbatch_016rrH1m8ACbxr7gtdeP4z8d\")\n",
    "kg_builder_batch = BuildGraphIndexBatch()\n",
    "kg_builder_batch.save_batch_results(results)\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.knowledge_graph_batch import BuildGraphIndexBatch\n",
    "kg_builder_batch = BuildGraphIndexBatch()\n",
    "results = kg_builder_batch.load_batch_results()\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Knowledge Graph\n",
    "Process through each of the results. The results contain the triplets.  Processing means writing the triplets into neo4j to build the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from src.knowledge_graph_batch import BuildGraphIndexBatch\n",
    "kg_builder_batch = BuildGraphIndexBatch()\n",
    "client = anthropic.Anthropic()\n",
    "results = kg_builder_batch.load_batch_results()\n",
    "kg_builder_batch.process_batch_results(text_nodes, results,database_name='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Token Use\n",
    "To understand the system, I built the graph using two simple files and one far more rich in content. \n",
    "- `ph.md`\n",
    "- `Focusing on Calcium Nutrition.md`\n",
    "- `soil_science_notes.md`\n",
    "I used mistral to build the graph.\n",
    "\n",
    "I then used DB Browser to view the token count.  The SQL Query: `select sum(\"completion_tokens\") from \"token_usage\"` returned  9144 tokens. The query: `select sum(\"prompt_tokens\") from \"token_usage\"` returns 30,260 tokens.\n",
    "\n",
    "This is just for 3 files.  There are far more documents than just this three to put into the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval\n",
    "Now let's do retrieval.  For a knowledge graph, we have nodes and a relationship so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.knowledge_graph import RetrieveGraphNodes\n",
    "retriever = RetrieveGraphNodes()\n",
    "nodes = retriever.retrieve(\"What is the ideal ph for growing Cannabis?\",database_name=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
