{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph Triplet Extraction Model Comparison\n",
    "## Overview\n",
    "We tested four different LLMs for extracting knowledge graph triplets from agricultural/plant science text:\n",
    "-   Claude 3.5 Sonnet\n",
    "- Mistral\n",
    "- Gemma 2\n",
    "Llama 3.2\n",
    "## Model Comparison\n",
    "### Claude 3.5 Sonnet\n",
    "- Best Overall Performance\n",
    "- Lowest token usage (445 avg/test)\n",
    "- Perfect max triplets compliance\n",
    "- Most consistent output format\n",
    "- Proper capitalization handling\n",
    "- Some API stability issues\n",
    "- Minor issues with compound objects\n",
    "### Mistral\n",
    "- Second Best\n",
    "- Good reliability\n",
    "- Fast execution\n",
    "- Higher token usage (855 avg/test)\n",
    "- Occasional max_triplet violations\n",
    "- Issues with compound concepts\n",
    "### Gemma 2\n",
    "- Mixed Performance\n",
    "- Good max_triplets compliance\n",
    "- Lower token usage than Mistral\n",
    "- Serious hallucination issues\n",
    "- Very slow execution (5-11s per request)\n",
    "- Issues with compound subjects\n",
    "### Llama 3.2\n",
    "- Poorest Performance\n",
    "- Significant hallucination\n",
    "- Inconsistent output format\n",
    "- Multiple max_triplet violations\n",
    "- Template leakage issues\n",
    "## Key Challenges Identified\n",
    "1. Compound Concepts: All models struggle with breaking down complex concepts into atomic units\n",
    "- Max Triplets: Most models occasionally exceed requested triplet limits\n",
    "- Hallucination: Particularly problematic in Gemma 2 and Llama 3.2\n",
    "- Token Efficiency: Wide variance in token usage across models\n",
    "\n",
    "## Recommendation\n",
    "Claude 3.5 Sonnet appears to be the best choice for knowledge graph triplet extraction due to:\n",
    "- Best token efficiency\n",
    "- Most reliable output\n",
    "- Consistent formatting\n",
    "- Proper handling of capitalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "For each Ollama model, I create a system prompt, e.g.:\n",
    "```\n",
    "FROM mistral\n",
    "# sets the temperature to 1 [higher is more creative, lower is more coherent]\n",
    "PARAMETER temperature 0.01\n",
    "\n",
    "\n",
    "# sets a custom system message to specify the behavior of the chat assistant\n",
    "SYSTEM \"\"\"You are a knowledge graph triplet extractor. Your task is to convert input text into knowledge triplets in the format (subject, PREDICATE, object).\n",
    "\n",
    "STRICT REQUIREMENTS:\n",
    "1. Extract ONLY the requested number of triplets\n",
    "2. ONLY use words that appear in the input text\n",
    "3. NEVER create relationships that aren't explicitly stated\n",
    "4. Keep all concepts ATOMIC - use single words whenever possible:\n",
    "   - For subjects: use the main noun (e.g., \"calcium\" not \"calcium_uptake\")\n",
    "   - For objects: use the target noun (e.g., \"xylem\" not \"xylem_to_leaves\")\n",
    "   - Only combine words if meaning is lost (e.g., \"carbon_dioxide\" is OK)\n",
    "\n",
    "FORMAT RULES:\n",
    "- Predicates: UPPERCASE with underscores\n",
    "- Subjects/objects: lowercase, prefer single words\n",
    "- Use hyphens for ranges (e.g., 6.8-6.9)\n",
    "\n",
    "EXAMPLES:\n",
    "\"Calcium is taken up by the xylem\"\n",
    "Good: (calcium, IS_TAKEN_UP_BY, xylem)\n",
    "Bad: (calcium, MOVES_TO, xylem_to_leaves)\n",
    "\n",
    "\"Plants lack phosphorus\"\n",
    "Good: (plants, LACK, phosphorus)\n",
    "Bad: (phosphorus_deficient_plants, SHOW, symptoms)\n",
    "\n",
    "\"The pH is 6.8-6.9\"\n",
    "Good: (ph, IS, 6.8-6.9)\n",
    "Bad: (optimal_ph_range, EQUALS, 6.8_to_6.9)\"\"\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# The code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "import spacy\n",
    "\n",
    "from src.knowledge_graph import BuildGraphIndex\n",
    "\n",
    "\n",
    "def analyze_sentence_structure(text: str):\n",
    "    \"\"\"Analyze the dependency structure of a sentence using SpaCy.\"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "\n",
    "    print(\"\\nSpaCy Dependency Analysis:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Token':<15} {'Dep':<12} {'Head':<15} {'Children'}\")\n",
    "    print(\"-\" * 60)\n",
    "    for token in doc:\n",
    "        children = [child.text for child in token.children]\n",
    "        print(f\"{token.text:<15} {token.dep_:<12} {token.head.text:<15} {children}\")\n",
    "\n",
    "    # Count relationships\n",
    "    subjects = [t for t in doc if t.dep_ in (\"nsubj\", \"nsubjpass\")]\n",
    "    objects = [t for t in doc if t.dep_ in (\"dobj\", \"pobj\")]\n",
    "\n",
    "    print(\"\\nRelationship Analysis:\")\n",
    "    print(f\"Subjects found: {[t.text for t in subjects]}\")\n",
    "    print(f\"Objects found: {[t.text for t in objects]}\")\n",
    "    relationship_count = len([sent for sent in doc.sents\n",
    "        if any(tok.dep_ in (\"nsubj\", \"nsubjpass\") for tok in sent)\n",
    "        and any(tok.dep_ in (\"dobj\", \"pobj\") for tok in sent)])\n",
    "    print(f\"Relationship count: {relationship_count}\")\n",
    "\n",
    "def test_triplet_extraction():\n",
    "    # Test cases with expected outputs\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"text\": \"Calcium is taken up by the xylem to the leaves.\",\n",
    "            \"max_triplets\": 1,\n",
    "            \"expected_triplets\": [\n",
    "                (\"xylem\", \"TRANSPORTS\", \"calcium\")\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Plants that are deficient of phosphorus will tend to be lighter in color, short and many times will display a reddish coloration from the accumulation of sugars in the plant.\",\n",
    "            \"max_triplets\": 2,\n",
    "            \"expected_triplets\": [\n",
    "                (\"phosphorus_deficiency\", \"CAUSES\", \"light_color\"),\n",
    "                (\"phosphorus_deficiency\", \"CAUSES\", \"short_plants\")\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"The ideal pH for growing Cannabis is between 6.8-6.9.\",\n",
    "            \"max_triplets\": 1,\n",
    "            \"expected_triplets\": [\n",
    "                (\"Cannabis_pH\", \"OPTIMAL_VALUE_IS\", \"6.8-6.9\")\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    builder = BuildGraphIndex()\n",
    "    results = []\n",
    "\n",
    "    for test_case in test_cases:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Testing text: {test_case['text']}\")\n",
    "\n",
    "        # Add SpaCy analysis\n",
    "        analyze_sentence_structure(test_case['text'])\n",
    "\n",
    "        print(f\"\\nMax triplets: {test_case['max_triplets']}\")\n",
    "        print(\"Expected triplets:\")\n",
    "        for t in test_case['expected_triplets']:\n",
    "            print(f\"  {t}\")\n",
    "\n",
    "        # Get actual results\n",
    "        result = builder._extract_triplets_with_retries(\n",
    "            text=test_case['text'],\n",
    "            max_triplets=test_case['max_triplets'],\n",
    "            model_name=\"claude-3-5-sonnet-20241022\"\n",
    "        )\n",
    "\n",
    "        print(\"\\nActual triplets:\")\n",
    "        if result['triplets']:\n",
    "            for t in result['triplets']:\n",
    "                print(f\"  {t}\")\n",
    "        else:\n",
    "            print(\"  No triplets returned\")\n",
    "\n",
    "        # Analysis\n",
    "        analysis = {\n",
    "            \"text\": test_case['text'],\n",
    "            \"max_triplets_requested\": test_case['max_triplets'],\n",
    "            \"triplets_returned\": len(result['triplets']) if result['triplets'] else 0,\n",
    "            \"respects_max_triplets\": (len(result['triplets']) if result['triplets'] else 0) <= test_case['max_triplets'],\n",
    "            \"raw_response\": result['response'],\n",
    "            \"token_usage\": result['token_usage']\n",
    "        }\n",
    "\n",
    "\n",
    "        results.append(analysis)\n",
    "\n",
    "        print(\"\\nAnalysis:\")\n",
    "        print(f\"Respects max triplets: {analysis['respects_max_triplets']}\")\n",
    "        print(f\"Token usage: {analysis['token_usage']}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run triplet extraction tests and analyze results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"\\nStarting Knowledge Graph Triplet Extraction Tests\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Run tests\n",
    "        results = test_triplet_extraction()\n",
    "\n",
    "        # Summary report\n",
    "        print(\"\\nSUMMARY REPORT\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Total test cases run: {len(results)}\")\n",
    "\n",
    "        # Compliance stats\n",
    "        max_triplet_violations = sum(1 for r in results if not r['respects_max_triplets'])\n",
    "\n",
    "        print(\"\\nCompliance Metrics:\")\n",
    "        print(f\"- Max triplet violations: {max_triplet_violations}/{len(results)}\")\n",
    "\n",
    "        # Token usage stats\n",
    "        total_tokens = sum(r['token_usage']['total_tokens'] for r in results)\n",
    "        avg_tokens = total_tokens / len(results)\n",
    "        print(\"\\nToken Usage:\")\n",
    "        print(f\"- Total tokens: {total_tokens}\")\n",
    "        print(f\"- Average tokens per test: {avg_tokens:.2f}\")\n",
    "\n",
    "        # Detailed results\n",
    "        print(\"\\nDETAILED RESULTS\")\n",
    "        print(\"=\" * 50)\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\nTest Case {i}:\")\n",
    "            print(f\"Text: {result['text'][:100]}...\")\n",
    "            print(f\"Requested triplets: {result['max_triplets_requested']}\")\n",
    "            print(f\"Received triplets: {result['triplets_returned']}\")\n",
    "            print(f\"Token usage: {result['token_usage']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "The run the command:\n",
    "```\n",
    "ollama create mistral_triplets -f mistral_triplets_modelfile\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
