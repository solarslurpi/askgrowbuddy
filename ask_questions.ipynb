{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This exploration is part of the AskGrowBuddy project that uses notes from Obsidian to provide growing knowledge.  The notebook explores having an LLM generate questions from a bunch of Obsidian notes.  To do this, the Langchain Obsidian document loader is used to load documents from a directory within an Obsidian vault. The Langchain Obsidian loader is used because it understands how to convert frontmatter to metadata. Obsidian notes typically hold metadata that is helpful in RAG.  I am not exploring metadata here but it is something to look into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Obsidian Notes\n",
    "Load the Obsidian vault directory into Langchain documents using Langchain's obsidian loader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in c:\\users\\happy\\documents\\projects\\askgrowbuddy\\.venv\\lib\\site-packages (1.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingest_service import IngestService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_service = IngestService()\n",
    "docs = ingest_service.load_docs(r\"G:\\My Drive\\Audios_To_Knowledge\\knowledge\\AskGrowBuddy\\AskGrowBuddy\\Knowledge\\Question_Answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Content\n",
    "Random check to see if the content was loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_content(docs, search_text):\n",
    "    for i, doc in enumerate(docs):\n",
    "        if search_text.lower() in doc.page_content.lower():\n",
    "            print(f\"Found in document {i}:\")\n",
    "            print(\"Metadata:\")\n",
    "            for key, value in doc.metadata.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "            print(\"\\nContent preview:\")\n",
    "            print(doc.page_content[:200] + \"...\")\n",
    "            print(\"\\n---\\n\")\n",
    "\n",
    "# Example usage\n",
    "search_text = \"A new book from Steve Solomon is reason \"\n",
    "search_content(docs, search_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1111"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Langchain docs to llamaindex docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 12\n",
      "First LlamaIndex Document:\n",
      "Text preview: # Sulfur\n",
      "\n",
      "Sulfur, in partnership with nitrogen, forms key pieces in several essential amino acids an...\n",
      "Metadata: {'source': 'Sulfur.md', 'path': 'G:\\\\My Drive\\\\Audios_To_Knowledge\\\\knowledge\\\\AskGrowBuddy\\\\AskGrowBuddy\\\\Knowledge\\\\Question_Answer\\\\soil test comments\\\\Sulfur.md', 'created': 1726950458.11, 'last_modified': 1725585368.506, 'last_accessed': 1726950458.11}\n"
     ]
    }
   ],
   "source": [
    "# Convert langchain Document to llamaindex document\n",
    "from llama_index.core import Document as LlamaDocument\n",
    "\n",
    "def convert_to_llama_documents(langchain_docs):\n",
    "    llama_docs = []\n",
    "    for lc_doc in langchain_docs:\n",
    "        llama_doc = LlamaDocument(\n",
    "            text=lc_doc.page_content,\n",
    "            metadata=lc_doc.metadata\n",
    "        )\n",
    "        llama_docs.append(llama_doc)\n",
    "    return llama_docs\n",
    "\n",
    "# Convert the documents\n",
    "llama_index_docs = convert_to_llama_documents(docs)\n",
    "\n",
    "# Print the first document to verify\n",
    "if llama_index_docs:\n",
    "    print(f\"Number of docs: {len(llama_index_docs)}\")\n",
    "    print(\"First LlamaIndex Document:\")\n",
    "    print(f\"Text preview: {llama_index_docs[0].text[:100]}...\")\n",
    "    print(f\"Metadata: {llama_index_docs[0].metadata}\")\n",
    "else:\n",
    "    print(\"No documents were converted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# Set embedding model\n",
    "ollama_embedding = OllamaEmbedding(\n",
    "    model_name=\"all-minilm\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")\n",
    "\n",
    "# Configure Ollama LLM\n",
    "llm = Ollama(model=\"llama3.1\", temperature=0, request_timeout=1000.0)\n",
    "#\n",
    "# Configure Settings singleton\n",
    "Settings.embed_model = ollama_embedding\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Token Tracking\n",
    "I want to know how many tokens are being used with the LLM in case I want to use a paid service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from llama_index.core.callbacks import CallbackManager, TokenCountingHandler\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Create a TokenCountingHandler instance\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\n",
    ")\n",
    "Settings.callback_manager = CallbackManager([token_counter])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am getting PoolTimeout.  This means the connection pool used by the client to make requests to Ollama has reached its maximum capacity and no additional connections are available within the specified timeout period.\n",
    "- Adding time to `llm = Ollama(model=\"llama3.1\", temperature=0, request_timeout=1000.0)`. The default for request_timeout is 30.0. Now it is still running 15 minutes later.  We'll see.\n",
    "- The request_timeout had it running a lot longer. But ultimately came to the same failure point.  I am thinking it is the size of the number of documents. Maybe it is made to best ask questions over one document.\n",
    "- now trying adding num_questions_per_chunk=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 12/12 [00:00<00:00, 246.98it/s]\n",
      "100%|██████████| 31/31 [02:31<00:00,  4.90s/it]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llama_dataset.generator import  RagDatasetGenerator\n",
    "from llama_index.core.prompts import Prompt\n",
    " # generate questions\n",
    "# %env OLLAMA_KEEP_ALIVE=3600\n",
    "data_generator = RagDatasetGenerator.from_documents(\n",
    "    llama_index_docs,\n",
    "    num_questions_per_chunk=1,\n",
    "    show_progress=True,\n",
    "    text_question_template=Prompt(\n",
    "        \"A sample from the LlamaIndex documentation is below.\\n\"\n",
    "        \"---------------------\\n\"\n",
    "        \"{context_str}\\n\"\n",
    "        \"---------------------\\n\"\n",
    "        \"Using the documentation sample, carefully follow the instructions below:\\n\"\n",
    "        \"{query_str}\"\n",
    "    ),\n",
    "    question_gen_query=(\n",
    "        \"You are an evaluator for a search pipeline. Your task is to write a single question \"\n",
    "        \"using the provided documentation sample above to test the search pipeline. The question should \"\n",
    "        \"reference specific names, functions, and terms. Restrict the question to the \"\n",
    "        \"context information provided.\\n\"\n",
    "        \"Question: \"\n",
    "    )\n",
    ")\n",
    "generated_questions = data_generator.generate_questions_from_nodes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_generator.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [02:37<00:00,  5.07s/it]\n"
     ]
    }
   ],
   "source": [
    "rag_dataset = data_generator.generate_questions_from_nodes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here's a question that tests the search pipeli...</td>\n",
       "      <td>[# Sulfur\\n\\nSulfur, in partnership with nitro...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[#soil_test  #cation_ratio #M3 #Mehlic-3 #satu...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[```mermaid\\npie\\n    title Cation Ration\\n   ...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[#soil_test  #M3 #Mehlic-3 #SP #saturated_past...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[#soil_test  #M3 #Mehlic-3 #SP #saturated_past...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[# my comments on 2021-11 Results\\n\\n[[SP_2023...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[This grow period, I liberally applied Mammoth...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[### SP -  Available Phosphorous\\n**SP Target ...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[Brandon stresses that while it is essential t...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[## Magnesium\\n\\n![[M3 Magnesium lbs_acre.png|...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[![[M3_Sodium_lbs_acre.png|450]]\\n\\nThe sodium...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[#soil_test  #M3 #Mehlic-3 #SP #saturated_past...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[Target value for Magnesium is 350 lbs/acre.\\n...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[If they're 171 and 93, I wouldn't flinch abou...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Here's a question that tests the search pipeli...</td>\n",
       "      <td>[- Back to Phosphate.  The Phosphate number of...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Here's a question that tests the search pipeli...</td>\n",
       "      <td>[It should be more, it should give us a better...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[They are getting readings far greater than 2....</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[We have 12.63 in the soil.  This makes for a ...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[#soil_test  #M3 #Mehlic-3 #SP #saturated_past...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Here's a question that can be used to test the...</td>\n",
       "      <td>[There is almost always plenty of trace availa...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Here's a question that tests the search pipeli...</td>\n",
       "      <td>[Use this document as a \"cheat sheet\" for prov...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[Without enough boron, plants cannot \"drink\" e...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[This document serves as a \"cheat sheet\" for a...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Here's a question that tests the search pipeli...</td>\n",
       "      <td>[## pH\\n### Importance\\npH is crucial for nutr...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[It's often a limiting nutrient in soil.\\n### ...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[Potassium is crucial for plant growth, water ...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[Importance: The balance of these cations affe...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[Saturated Paste: The magnesium level appears ...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[Importance: According to Steve Solomon (The I...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Here's a question that tests the search pipeli...</td>\n",
       "      <td>[You are assisting in writing up a soil analys...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Here's a question based on the provided docume...</td>\n",
       "      <td>[- Date: &lt;fill in data of soil test analysis b...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   Here's a question that tests the search pipeli...   \n",
       "1   Here's a question that can be used to test the...   \n",
       "2   Here's a question that can be used to test the...   \n",
       "3   Here's a question that can be used to test the...   \n",
       "4   Here's a question that can be used to test the...   \n",
       "5   Here's a question that can be used to test the...   \n",
       "6   Here's a question based on the provided docume...   \n",
       "7   Here's a question based on the provided docume...   \n",
       "8   Here's a question that can be used to test the...   \n",
       "9   Here's a question that can be used to test the...   \n",
       "10  Here's a question that can be used to test the...   \n",
       "11  Here's a question based on the provided docume...   \n",
       "12  Here's a question based on the provided docume...   \n",
       "13  Here's a question that can be used to test the...   \n",
       "14  Here's a question that tests the search pipeli...   \n",
       "15  Here's a question that tests the search pipeli...   \n",
       "16  Here's a question that can be used to test the...   \n",
       "17  Here's a question that can be used to test the...   \n",
       "18  Here's a question that can be used to test the...   \n",
       "19  Here's a question that can be used to test the...   \n",
       "20  Here's a question that tests the search pipeli...   \n",
       "21  Here's a question based on the provided docume...   \n",
       "22  Here's a question based on the provided docume...   \n",
       "23  Here's a question that tests the search pipeli...   \n",
       "24  Here's a question based on the provided docume...   \n",
       "25  Here's a question based on the provided docume...   \n",
       "26  Here's a question based on the provided docume...   \n",
       "27  Here's a question based on the provided docume...   \n",
       "28  Here's a question based on the provided docume...   \n",
       "29  Here's a question that tests the search pipeli...   \n",
       "30  Here's a question based on the provided docume...   \n",
       "\n",
       "                                   reference_contexts reference_answer  \\\n",
       "0   [# Sulfur\\n\\nSulfur, in partnership with nitro...                    \n",
       "1   [#soil_test  #cation_ratio #M3 #Mehlic-3 #satu...                    \n",
       "2   [```mermaid\\npie\\n    title Cation Ration\\n   ...                    \n",
       "3   [#soil_test  #M3 #Mehlic-3 #SP #saturated_past...                    \n",
       "4   [#soil_test  #M3 #Mehlic-3 #SP #saturated_past...                    \n",
       "5   [# my comments on 2021-11 Results\\n\\n[[SP_2023...                    \n",
       "6   [This grow period, I liberally applied Mammoth...                    \n",
       "7   [### SP -  Available Phosphorous\\n**SP Target ...                    \n",
       "8   [Brandon stresses that while it is essential t...                    \n",
       "9   [## Magnesium\\n\\n![[M3 Magnesium lbs_acre.png|...                    \n",
       "10  [![[M3_Sodium_lbs_acre.png|450]]\\n\\nThe sodium...                    \n",
       "11  [#soil_test  #M3 #Mehlic-3 #SP #saturated_past...                    \n",
       "12  [Target value for Magnesium is 350 lbs/acre.\\n...                    \n",
       "13  [If they're 171 and 93, I wouldn't flinch abou...                    \n",
       "14  [- Back to Phosphate.  The Phosphate number of...                    \n",
       "15  [It should be more, it should give us a better...                    \n",
       "16  [They are getting readings far greater than 2....                    \n",
       "17  [We have 12.63 in the soil.  This makes for a ...                    \n",
       "18  [#soil_test  #M3 #Mehlic-3 #SP #saturated_past...                    \n",
       "19  [There is almost always plenty of trace availa...                    \n",
       "20  [Use this document as a \"cheat sheet\" for prov...                    \n",
       "21  [Without enough boron, plants cannot \"drink\" e...                    \n",
       "22  [This document serves as a \"cheat sheet\" for a...                    \n",
       "23  [## pH\\n### Importance\\npH is crucial for nutr...                    \n",
       "24  [It's often a limiting nutrient in soil.\\n### ...                    \n",
       "25  [Potassium is crucial for plant growth, water ...                    \n",
       "26  [Importance: The balance of these cations affe...                    \n",
       "27  [Saturated Paste: The magnesium level appears ...                    \n",
       "28  [Importance: According to Steve Solomon (The I...                    \n",
       "29  [You are assisting in writing up a soil analys...                    \n",
       "30  [- Date: <fill in data of soil test analysis b...                    \n",
       "\n",
       "   reference_answer_by       query_by  \n",
       "0                 None  ai (llama3.1)  \n",
       "1                 None  ai (llama3.1)  \n",
       "2                 None  ai (llama3.1)  \n",
       "3                 None  ai (llama3.1)  \n",
       "4                 None  ai (llama3.1)  \n",
       "5                 None  ai (llama3.1)  \n",
       "6                 None  ai (llama3.1)  \n",
       "7                 None  ai (llama3.1)  \n",
       "8                 None  ai (llama3.1)  \n",
       "9                 None  ai (llama3.1)  \n",
       "10                None  ai (llama3.1)  \n",
       "11                None  ai (llama3.1)  \n",
       "12                None  ai (llama3.1)  \n",
       "13                None  ai (llama3.1)  \n",
       "14                None  ai (llama3.1)  \n",
       "15                None  ai (llama3.1)  \n",
       "16                None  ai (llama3.1)  \n",
       "17                None  ai (llama3.1)  \n",
       "18                None  ai (llama3.1)  \n",
       "19                None  ai (llama3.1)  \n",
       "20                None  ai (llama3.1)  \n",
       "21                None  ai (llama3.1)  \n",
       "22                None  ai (llama3.1)  \n",
       "23                None  ai (llama3.1)  \n",
       "24                None  ai (llama3.1)  \n",
       "25                None  ai (llama3.1)  \n",
       "26                None  ai (llama3.1)  \n",
       "27                None  ai (llama3.1)  \n",
       "28                None  ai (llama3.1)  \n",
       "29                None  ai (llama3.1)  \n",
       "30                None  ai (llama3.1)  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Tokens:  0 \n",
      " LLM Prompt Tokens:  54544 \n",
      " LLM Completion Tokens:  6176 \n",
      " Total LLM Token Count:  60720 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Embedding Tokens: \",\n",
    "    token_counter.total_embedding_token_count,\n",
    "    \"\\n\",\n",
    "    \"LLM Prompt Tokens: \",\n",
    "    token_counter.prompt_llm_token_count,\n",
    "    \"\\n\",\n",
    "    \"LLM Completion Tokens: \",\n",
    "    token_counter.completion_llm_token_count,\n",
    "    \"\\n\",\n",
    "    \"Total LLM Token Count: \",\n",
    "    token_counter.total_llm_token_count,\n",
    "    \"\\n\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
